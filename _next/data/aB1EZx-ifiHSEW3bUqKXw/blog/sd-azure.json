{"pageProps":{"id":"sd-azure","meta":{"title":"Run Stable Diffusion in Azure","description":"Hardware requirement are pretty challenging for most of the machine learning needs, stable diffusion is no different. I've an Azure subscription can I make use of that?","published":false,"publishedAt":"2023-01-16T00:00:00.000Z","updatedAt":"2023-01-16T00:00:00.000Z","category":"tech","image":"banners/69","keywords":["azure","stable-diffusion","machine-learning"],"authors":["Krishna Mohan A M"]},"content":"<p>Hardware requirement are pretty challenging for most of the machine learning needs, stable diffusion is no different. Most of the SaaS offerings' pricing (Dreamstudio, Midjourney) depends on the number of images generated. My intention was totally different than just generating cool images, I want to play around with it and learn how it works.</p>\n<p>But wait, I've an Azure subscription. Can I make use of that? I googled around and found a <a href=\"https://vladiliescu.net/stable-diffusion-web-ui-on-azure-ml/\">very informative blog</a> to spin-off an Azure ML instance to run SD. I followed most of that blog with some tweaks for my needs. If you prefer to follow the original reference please do so.</p>\n<h2>Prerequisites</h2>\n<ul>\n<li>Install <a href=\"https://learn.microsoft.com/en-us/cli/azure/install-azure-cli\">Azure CLI</a> and its <a href=\"https://learn.microsoft.com/en-us/azure/machine-learning/how-to-configure-cli?tabs=public\">ML extension</a></li>\n<li>Login to Azure from CLI and set the default subscription.\n<div class=\"remark-highlight\"><pre class=\"language-powershell\"><code class=\"language-powershell\"><span class=\"token comment\"># Log in with your Azure account. This will open webpage, login with your credentials.</span>\naz login\n\n<span class=\"token comment\"># List your available subscriptions. Check IsDefault flag to know which one is default</span>\naz account list <span class=\"token operator\">--</span>output table\n\n<span class=\"token comment\"># Set your default subscription. </span>\naz account <span class=\"token function\">set</span> <span class=\"token operator\">--</span>subscription <span class=\"token string\">\"&#x3C;your-subscription-id>\"</span>\n</code></pre></div>\n</li>\n<li>Get a <a href=\"https://huggingface.co/docs/hub/security-tokens#how-to-use-user-access-tokens\">Hugging Face User Access Token</a>. This is required to download models.</li>\n</ul>\n<h2>Setup Azure ML instance</h2>\n<ul>\n<li>Create a resource group. I chose <code>eastus</code> due to its low cost compared to other regions.\n<div class=\"remark-highlight\"><pre class=\"language-powershell\"><code class=\"language-powershell\">az <span class=\"token function\">group</span> create <span class=\"token operator\">--</span>name <span class=\"token string\">\"rg-stable-diffusion\"</span> <span class=\"token operator\">--</span>location <span class=\"token string\">\"eastus\"</span>\n</code></pre></div>\n</li>\n<li>Create an ML workspace - youâ€™ll need this to do anything ML-related in Azure.\n<div class=\"remark-highlight\"><pre class=\"language-powershell\"><code class=\"language-powershell\">az ml workspace create <span class=\"token operator\">-</span>n <span class=\"token string\">\"ml-stable-diffusion\"</span> <span class=\"token operator\">-</span>g <span class=\"token string\">\"rg-stable-diffusion\"</span>\n</code></pre></div>\n</li>\n<li>This step is mildly complex and varies depends on your subscription. I had a Visual Studio Subscription and some of the higher compute instances are forbidden in that.\n<div class=\"remark-highlight\"><pre class=\"language-powershell\"><code class=\"language-powershell\"><span class=\"token comment\"># Command to list compute instances with GPU</span>\naz ml compute list-sizes <span class=\"token operator\">-</span>l eastus <span class=\"token operator\">-</span>w <span class=\"token string\">\"ml-stable-diffusion\"</span> <span class=\"token operator\">-</span>g <span class=\"token string\">\"rg-stable-diffusion\"</span> <span class=\"token operator\">--</span>output table <span class=\"token operator\">--</span>query <span class=\"token string\">\"[?gpus > ``0``, v_cp_us > ``0``].{Name:name, Gpus:gpus, vCPU:v_cp_us}\"</span>\n</code></pre></div>\n<ul>\n<li>Open an new <code>YAML</code> file, say <code>compute.yaml</code>, with the details below. I tried with <code>Standard_NC6s_v3</code> firt, but due to my subscriptions limit, I had to switch to <code>Standard_NV6</code>. Refer the <a href=\"https://azure.microsoft.com/en-us/pricing/details/machine-learning/#NV-series\">pricing details</a> for better understanding.\n<div class=\"remark-highlight\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">$schema</span><span class=\"token punctuation\">:</span> https<span class=\"token punctuation\">:</span>//azuremlschemas.azureedge.net/latest/computeInstance.schema.json \n\n<span class=\"token comment\"># this name is globally unique, please choose a different name</span>\n<span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> ksd<span class=\"token punctuation\">-</span>tin<span class=\"token punctuation\">-</span>tin\n<span class=\"token key atrule\">type</span><span class=\"token punctuation\">:</span> computeinstance\n\n<span class=\"token comment\">#</span>\n<span class=\"token key atrule\">size</span><span class=\"token punctuation\">:</span> Standard_NV6\n<span class=\"token key atrule\">idle_time_before_shutdown_minutes</span><span class=\"token punctuation\">:</span> <span class=\"token number\">15</span>\n</code></pre></div>\n</li>\n<li>Run the CLI command to create instance. This will take couple of minutes. Once done you can check the status in <a href=\"https://ml.azure.com/\">Azure ML Studio</a> or in CLI.\n<div class=\"remark-highlight\"><pre class=\"language-powershell\"><code class=\"language-powershell\">az ml compute create <span class=\"token operator\">-</span>f compute<span class=\"token punctuation\">.</span>yml <span class=\"token operator\">-</span>w <span class=\"token string\">\"ml-stable-diffusion\"</span> <span class=\"token operator\">-</span>g <span class=\"token string\">\"rg-stable-diffusion\"</span>\n</code></pre></div>\n</li>\n</ul>\n</li>\n</ul>\n<h2>Setup Stable Diffusion Web UI</h2>\n<p>Multiple WebUIs are available like <a href=\"https://github.com/Sygil-Dev/sygil-webui\">sygil-webui</a>, <a href=\"https://github.com/AUTOMATIC1111/stable-diffusion-webui\">stable-diffusion-webui</a> and <a href=\"https://github.com/invoke-ai/InvokeAI\">InvokeAI</a>. Here we'll be using <code>stable-diffusion-webui</code>.</p>\n<ul>\n<li>Make sure your compute instance is running, then click its <code>Terminal</code> link to start a new terminal session.</li>\n<li>Clone the <code>AUTOMATIC1111/stable-diffusion-webui</code> repo.\n<div class=\"remark-highlight\"><pre class=\"language-powershell\"><code class=\"language-powershell\"><span class=\"token comment\"># Clone the SD WebUI</span>\ngit clone https:<span class=\"token operator\">/</span><span class=\"token operator\">/</span>github<span class=\"token punctuation\">.</span>com/AUTOMATIC1111/stable-diffusion-webui<span class=\"token punctuation\">.</span>git\n\n<span class=\"token comment\"># Go to the models folder</span>\ncd stable-diffusion-webui/models/Stable-diffusion/\n</code></pre></div>\n</li>\n<li>Download SD2.1 model from Hugging Face.\n<div class=\"remark-highlight\"><pre class=\"language-powershell\"><code class=\"language-powershell\"><span class=\"token comment\"># Download the x768 model, specifically the safetensors versions for increased security and loading speed</span>\ncurl <span class=\"token operator\">-</span>H <span class=\"token string\">\"Authorization: Bearer &#x3C;your-huggingface-token>\"</span> https:<span class=\"token operator\">/</span><span class=\"token operator\">/</span>huggingface<span class=\"token punctuation\">.</span>co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned<span class=\"token punctuation\">.</span>safetensors <span class=\"token operator\">--</span>location <span class=\"token operator\">--</span>output v2-1_768-ema-pruned<span class=\"token punctuation\">.</span>safetensors\n\n<span class=\"token comment\"># and its config as well</span>\ncurl https:<span class=\"token operator\">/</span><span class=\"token operator\">/</span>raw<span class=\"token punctuation\">.</span>githubusercontent<span class=\"token punctuation\">.</span>com/Stability-AI/stablediffusion/main/configs/stable-diffusion/v2-inference-v<span class=\"token punctuation\">.</span>yaml <span class=\"token operator\">--</span>output v2-1_768-ema-pruned<span class=\"token punctuation\">.</span>yaml\n</code></pre></div>\n</li>\n<li>Install web ui's dependencies. This will take few minutes to complete.\n<div class=\"remark-highlight\"><pre class=\"language-powershell\"><code class=\"language-powershell\"><span class=\"token comment\"># Create a new Conda env with the desired Python version</span>\nconda create <span class=\"token operator\">-</span>n a1111-sdwebui python=3<span class=\"token punctuation\">.</span>10 <span class=\"token operator\">-</span>y\n\n<span class=\"token comment\"># Activate the new env</span>\nconda activate a1111-sdwebui\n\n<span class=\"token comment\"># Go back to the root of the repo..</span>\ncd <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token operator\">/</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\n\n<span class=\"token comment\"># ..so we can install the repository's dependencies..</span>\npip install <span class=\"token operator\">-</span>r requirements_versions<span class=\"token punctuation\">.</span>txt \n\n<span class=\"token comment\"># ..which for some reason won't install everything leading to the web ui crashing </span>\n<span class=\"token comment\"># while complaining about `undefined symbol: cublasLtGetStatusString, version libcublasLt.so.11`</span>\n<span class=\"token comment\"># So, we need to install the missing dependencies directly from conda</span>\nconda install pytorch=1<span class=\"token punctuation\">.</span>13 torchvision=0<span class=\"token punctuation\">.</span>14 torchaudio=0<span class=\"token punctuation\">.</span>13 pytorch-cuda=11<span class=\"token punctuation\">.</span>7 <span class=\"token operator\">-</span>c pytorch <span class=\"token operator\">-</span>c nvidia <span class=\"token operator\">-</span>y\n\n\n<span class=\"token comment\"># If you want/need an older version, see the alternatives here https://pytorch.org/get-started/previous-versions/</span>\n<span class=\"token comment\"># e.g. I've had success with </span>\n<span class=\"token comment\"># conda install pytorch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 cudatoolkit=11.3 -c pytorch -y</span>\n\n<span class=\"token comment\"># Mark everything as a safe directory,</span>\n<span class=\"token comment\"># we need this because when first run,</span>\n<span class=\"token comment\"># the web ui will try to clone some repos under this directory, </span>\n<span class=\"token comment\"># and we'll get a lot of dubious ownership errors,</span>\n<span class=\"token comment\"># which we don't really want to be honest</span>\ngit config <span class=\"token operator\">--</span>global <span class=\"token operator\">--</span>add safe<span class=\"token punctuation\">.</span>directory <span class=\"token string\">'*'</span>\n</code></pre></div>\n</li>\n<li>Launch the web UI. This will also take couple of minutes as it requires some extra dependencies to start. If you don't provide username/password, someone will <a href=\"https://www.reddit.com/r/StableDiffusion/comments/y52yt0/why_are_there_images_i_never_generated_in_my/\">use your sytem</a> via open gradio share.\n<div class=\"remark-highlight\"><pre class=\"language-powershell\"><code class=\"language-powershell\">accelerate launch <span class=\"token operator\">--</span>mixed_precision=fp16 <span class=\"token operator\">--</span>num_cpu_threads_per_process=6 launch<span class=\"token punctuation\">.</span>py <span class=\"token operator\">--</span>precision full <span class=\"token operator\">--</span>no-half <span class=\"token operator\">--</span>share <span class=\"token operator\">--</span>gradio-auth &#x3C;user>:&#x3C;pass>\n</code></pre></div>\n</li>\n</ul>\n<h2>Run it again</h2>\n<p>Next time you want run SD, just run the follwoing commands.</p>\n<div class=\"remark-highlight\"><pre class=\"language-powershell\"><code class=\"language-powershell\"><span class=\"token comment\"># Activate the new env</span>\nconda activate a1111-sdwebui\n\n<span class=\"token comment\"># Launc</span>\naccelerate launch <span class=\"token operator\">--</span>mixed_precision=fp16 <span class=\"token operator\">--</span>num_cpu_threads_per_process=6 launch<span class=\"token punctuation\">.</span>py <span class=\"token operator\">--</span>precision full <span class=\"token operator\">--</span>no-half <span class=\"token operator\">--</span>share <span class=\"token operator\">--</span>gradio-auth &#x3C;user>:&#x3C;pass>\n</code></pre></div>\n<h2>Wrap Up</h2>\n<p>We can do a lot of improvements on top of it, like running image generation <a href=\"https://github.com/facebookresearch/xformers\">faster</a> or installing extensions. It's up to you to further explore the same.</p>\n"},"__N_SSG":true}